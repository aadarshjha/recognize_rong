{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg_facerecognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python_defaultSpec_1598652179111",
      "display_name": "Python 3.6.8 64-bit"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaS3xik7PJs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from scipy.spatial.distance import cosine"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvOuPbgBUCvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "197b5392-5d51-4178-d6a2-4d7c6bd9c7fe",
        "tags": []
      },
      "source": [
        "!pip install keras_applications\n",
        "!pip install git+https://github.com/rcmalli/keras-vggface.git"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: keras_applications in c:\\users\\rongw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (1.0.8)\nRequirement already satisfied: h5py in c:\\users\\rongw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras_applications) (2.10.0)\nRequirement already satisfied: numpy>=1.9.1 in c:\\users\\rongw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras_applications) (1.18.5)\nRequirement already satisfied: six in c:\\users\\rongw\\appdata\\roaming\\python\\python36\\site-packages (from h5py->keras_applications) (1.15.0)\nYou are using pip version 18.1, however version 20.2.2 is available.\nYou should consider upgrading via the 'python -m pip install --upgrade pip' command.\nCollecting git+https://github.com/rcmalli/keras-vggface.gitYou are using pip version 18.1, however version 20.2.2 is available.\nYou should consider upgrading via the 'python -m pip install --upgrade pip' command.\n\n  Cloning https://github.com/rcmalli/keras-vggface.git to c:\\users\\rongw\\appdata\\local\\temp\\pip-req-build-9luk465y\nRequirement already satisfied (use --upgrade to upgrade): keras-vggface==0.6 from git+https://github.com/rcmalli/keras-vggface.git in c:\\users\\rongw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\nRequirement already satisfied: numpy>=1.9.1 in c:\\users\\rongw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras-vggface==0.6) (1.18.5)\nRequirement already satisfied: scipy>=0.14 in c:\\users\\rongw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras-vggface==0.6) (1.4.1)\nRequirement already satisfied: h5py in c:\\users\\rongw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras-vggface==0.6) (2.10.0)\nRequirement already satisfied: pillow in c:\\users\\rongw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras-vggface==0.6) (7.2.0)\nRequirement already satisfied: keras in c:\\users\\rongw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras-vggface==0.6) (2.4.3)\nRequirement already satisfied: six>=1.9.0 in c:\\users\\rongw\\appdata\\roaming\\python\\python36\\site-packages (from keras-vggface==0.6) (1.15.0)\nRequirement already satisfied: pyyaml in c:\\users\\rongw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras-vggface==0.6) (5.3.1)\nBuilding wheels for collected packages: keras-vggface\n  Running setup.py bdist_wheel for keras-vggface: started\n  Running setup.py bdist_wheel for keras-vggface: finished with status 'done'\n  Stored in directory: C:\\Users\\rongw\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-5jgypnhk\\wheels\\36\\07\\46\\06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\nSuccessfully built keras-vggface\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYciNFwbi1dJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.utils import decode_predictions"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKX-1QMRbnun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_dir = 'faces/aligned/rong/'\n",
        "other_dir = 'faces/aligned/notrong/'"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46z4yUJrPQO8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "841e5305-97d0-4168-8b3f-714f99dc83ec",
        "tags": []
      },
      "source": [
        "model = VGGFace(include_top=False, input_shape=(244,244,3), pooling='avg')\n",
        "\n",
        "print(model.inputs)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[<tf.Tensor 'input_12:0' shape=(None, 244, 244, 3) dtype=float32>]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3CARHjKcL6u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "54da1fa7-3460-4bc1-b822-43182f82702c",
        "tags": []
      },
      "source": [
        "face_embeddings = []\n",
        "face_embeddings_not = []\n",
        "\n",
        "def get_embedding(image_path, model, image_size):\n",
        "  img = Image.open(image_path)\n",
        "  img = img.resize(image_size)\n",
        "  pix = np.array(img)\n",
        "  pix = pix.astype('float32')\n",
        "  pix = np.expand_dims(pix, axis=0)\n",
        "\n",
        "  face = preprocess_input(pix, version=2)\n",
        "  return model.predict(face)\n",
        "\n",
        "size = (244, 244)\n",
        "for file in os.listdir(image_dir):\n",
        "  face_embeddings.append(get_embedding(image_dir + file, model, size))\n",
        "\n",
        "for file in os.listdir(other_dir):\n",
        "  face_embeddings_not.append(get_embedding(other_dir + file, model, size))"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVKUblKMoTMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "a444ba9a-6ff8-4fdd-8cec-a71ead0ef036",
        "tags": []
      },
      "source": [
        "max = 0\n",
        "for i in range(len(face_embeddings)):\n",
        "  for j in range(i + 1, len(face_embeddings)):\n",
        "    dist = cosine(face_embeddings[i], face_embeddings[j])\n",
        "    if(max < dist): \n",
        "      max = dist\n",
        "\n",
        "print('highest distance bt photos of me: ', max)\n",
        "\n",
        "min_index = 0\n",
        "min_dist = 1\n",
        "for i in range(len(face_embeddings)):\n",
        "  for j in range(len(face_embeddings_not)):\n",
        "    dist = (cosine(face_embeddings[i], face_embeddings_not[j]))\n",
        "    if(dist < min_dist):\n",
        "      min_dist = dist\n",
        "      min_index = j\n",
        "\n",
        "print('most similar image dist value of not me: ' , min_dist)\n",
        "print('image index: ', min_index)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "highest distance bt photos of me:  0.24043625593185425\nmost similar image dist value of not me:  0.3000403642654419\nimage index:  3\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-xPE2Q4mtKY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "eea4bcb6-4f66-4f8c-b67a-1d672497bfd9",
        "tags": []
      },
      "source": [
        "vgg = VGGFace()\n",
        "\n",
        "for file in os.listdir(image_dir):\n",
        "  img = Image.open(image_dir + file)\n",
        "  img = img.resize(size)\n",
        "  pix = np.array(img)\n",
        "  pix = pix.astype('float32')\n",
        "  pix = np.expand_dims(pix, axis=0)\n",
        "\n",
        "  pix = preprocess_input(pix, version=2)\n",
        "  res = vgg.predict(pix)\n",
        "  results = decode_predictions(res)\n",
        "\n",
        "  print(results)\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_13:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 244, 244, 3).\n[[[\"b'Jake_Cherry'\", 0.034130726], [\"b'Sung_Kang'\", 0.03310631], [\"b'Sophie_Okonedo'\", 0.0274092], [\"b'Cierra_Ramirez'\", 0.026795443], [\"b'Britne_Oldford'\", 0.018653762]]]\n[[[\"b'Rico_Rodriguez'\", 0.10262949], [\"b'Sophie_Okonedo'\", 0.07488068], [\"b'Shonda_Rhimes'\", 0.047370546], [\"b'Raini_Rodriguez'\", 0.044577476], [\"b'David_Mamet'\", 0.038508985]]]\n[[[\"b'Toni_Trucks'\", 0.13743211], [\"b'Della_Reese'\", 0.054906514], [\"b'Reece_Thompson'\", 0.023407605], [\"b'Harry_Styles'\", 0.019214308], [\"b'Efren_Ramirez'\", 0.017902216]]]\n[[[\"b'Della_Reese'\", 0.18197499], [\"b'Toni_Trucks'\", 0.038251713], [\"b'Reece_Thompson'\", 0.017681155], [\"b'Loretta_Devine'\", 0.01573061], [\"b'Efren_Ramirez'\", 0.015394212]]]\n[[[\"b'Kali_Hawk'\", 0.054283492], [\"b'Reece_Thompson'\", 0.028296957], [\"b'Efren_Ramirez'\", 0.021056468], [\"b'Della_Reese'\", 0.018407248], [\"b'Dr._Dre'\", 0.0157496]]]\n[[[\"b'Kali_Hawk'\", 0.04814082], [\"b'Andy_Milonakis'\", 0.048020273], [\"b'Jimmy_Bennett'\", 0.04611696], [\"b'Kel_Mitchell'\", 0.04074806], [\"b'Dylan_Minnette'\", 0.021854537]]]\n[[[\"b'Retta'\", 0.054667518], [\"b'Aaron_Yoo'\", 0.03218082], [\"b'A.R._Rahman'\", 0.017643878], [\"b'Jenifer_Lewis'\", 0.015158306], [\"b'Efren_Ramirez'\", 0.013261669]]]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0.20365482568740845\n0.5448296070098877\n0.5288482904434204\n"
        }
      ],
      "source": [
        "rong = Image.open('faces/aligned/rong/face_0.jpg')\n",
        "rong1 = Image.open('faces/aligned/rong/face_1.jpg')\n",
        "\n",
        "rong = rong.resize(size)\n",
        "pix_rong = np.array(rong)\n",
        "pix_rong = pix_rong.astype('float32')\n",
        "pix_rong = np.expand_dims(pix_rong, axis=0)\n",
        "pix_rong = preprocess_input(pix_rong, version=2)\n",
        "res = model.predict(pix_rong)\n",
        "\n",
        "rong1 = rong1.resize(size)\n",
        "rong1 = rong1.resize(size)\n",
        "pix_rong1 = np.array(rong1)\n",
        "pix_rong1 = pix_rong1.astype('float32')\n",
        "pix_rong1 = np.expand_dims(pix_rong1, axis=0)\n",
        "pix_rong1 = preprocess_input(pix_rong1, version=2)\n",
        "res1 = model.predict(pix_rong1)\n",
        "\n",
        "notrong = Image.open('faces/aligned/notrong/face_0.jpg')\n",
        "notrong = notrong.resize(size)\n",
        "pix_not = np.array(notrong)\n",
        "pix_not = pix_not.astype('float32')\n",
        "pix_not = np.expand_dims(pix_not, axis=0)\n",
        "pix_not = preprocess_input(pix_not)\n",
        "res2 = model.predict(pix_not)\n",
        "\n",
        "print(cosine(res, res1))\n",
        "print(cosine(res, res2))\n",
        "print(cosine(res1, res2))\n"
      ]
    }
  ]
}